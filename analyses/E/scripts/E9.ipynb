{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96a33ff-40a6-44ed-9aaa-436a0dc84982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n"
     ]
    }
   ],
   "source": [
    "# Python script for analyses of \"Antibody affinity birth through somatic hypermutation\" publication.\n",
    "# This pipeline is divided into X sections. At the beginning of each section there is a comment which indicates which figures of the publication are generated based on that section.\n",
    "\n",
    "# input sequences for these analyses are uploaded in data folder. By a successful run, the result of each section will be saved in output folder.\n",
    "print('Running...')\n",
    "import re\n",
    "import operator\n",
    "\n",
    "import os\n",
    "#import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "#import logomaker #https://logomaker.readthedocs.io\n",
    "\n",
    "# Functions\n",
    "def display_big():\n",
    "\n",
    "    # df = pd.DataFrame()\n",
    "    # pd.options.display.max_colwidth = 2000\n",
    "    pd.set_option('display.max_rows', 10)\n",
    "    pd.set_option('display.max_columns', 200)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "display_big()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60c3d1b-a1c5-4d6c-946b-41fc40b8b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='../data'\n",
    "\n",
    "input_folder = os.getenv('VAR_IN_FOLDER', f\"{data_folder}/input\")\n",
    "output_folder = os.getenv('VAR_OUT_FOLDER', f\"{data_folder}/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0338a0-9a67-48f5-bb0b-f9b175c9c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_output_folder(section_output):\n",
    "    output_folder=data_folder+'/output/'+section_output\n",
    "\n",
    "    if not os.path.isdir(output_folder): # make output folder if it doesn't exist\n",
    "        os.makedirs(output_folder)\n",
    "    return(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9138cbc4-c997-4be4-ab6d-820e6ae7d28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Section1: preparation\n",
    "\n",
    "output_folder_prep=set_output_folder('1_prep')\n",
    "output_folder_num_miss=set_output_folder('2_num_miss')\n",
    "output_folder_freq_pos=set_output_folder('3_freq_per_position')\n",
    "output_folder_donuts=set_output_folder('4_donuts')\n",
    "output_folder_seq_logos=set_output_folder('5_seq_logos')\n",
    "output_folder_rs_prep=set_output_folder('6_prep_rs')\n",
    "output_folder_rs=set_output_folder('7_rs')\n",
    "output_folder_prep_plots=set_output_folder('8_prep_plots')\n",
    "output_folder_scatter_plots=set_output_folder('9_scatter_plots')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30808ec5-731d-4876-be6a-37240dc07db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_sign='-'\n",
    "ambiguity_sign='.'\n",
    "aas_dic={'AAA':'K','AAC':'N','AAT':'N','AAG':'K','ACA':'T','ACC':'T','ACT':'T','ACG':'T','ATA':'I','ATC':'I',\\\n",
    "        'ATT':'I','ATG':'M','AGA':'R','AGC':'S','AGT':'S','AGG':'R','CAA':'Q','CAC':'H','CAT':'H','CAG':'Q',\\\n",
    "        'CCA':'P','CCC':'P','CCT':'P','CCG':'P','CTA':'L','CTC':'L','CTT':'L','CTG':'L','CGA':'R','CGC':'R',\\\n",
    "        'CGT':'R','CGG':'R','TAA':'*','TAC':'Y','TAT':'Y','TAG':'*','TCA':'S','TCC':'S','TCT':'S','TCG':'S',\\\n",
    "        'TTA':'L','TTC':'F','TTT':'F','TTG':'L','TGA':'*','TGC':'C','TGT':'C','TGG':'W','GAA':'E','GAC':'D',\\\n",
    "        'GAT':'D','GAG':'E','GCA':'A','GCC':'A','GCT':'A','GCG':'A','GTA':'V','GTC':'V','GTT':'V','GTG':'V',\\\n",
    "        'GGA':'G','GGC':'G','GGT':'G','GGG':'G','---':del_sign}\n",
    "aas_list=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '*', del_sign]\n",
    "aas_chemistry_list=['I', 'V', 'L', 'F', 'C', 'M', 'A', 'W', 'G', 'T', 'S', 'Y', 'P', 'H', 'N', 'D', 'Q', 'E', 'K', 'R']\n",
    "nts_list=['A', 'C', 'G', 'T', del_sign, ambiguity_sign]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703f3f42-a79f-42fd-b810-c4e0d826699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_dic={ 1 : {'mouse' : 'B18-383', 'datasets': ['OVA', 'APC', 'CGG', 'Passenger'], 'chain':'VH'},\n",
    "            2 : {'mouse' : 'HA-WT', 'datasets': ['OVA', 'APC', 'CGG', 'mix'], 'chain':'VH'},\n",
    "           \n",
    "            3 : {'mouse' : 'B18-383', 'datasets': ['OVA-CTLA4', 'OVA-Isotype'], 'chain':'VH'},\n",
    "            4 : {'mouse' : 'HA-uMT', 'datasets': ['OVA-CTLA4', 'OVA-Isotype'], 'chain':'VH'},\n",
    "            5 : {'mouse' : 'HA-WT', 'datasets': ['CGG-CTLA4', 'CGG-Isotype'], 'chain':'VH'},\n",
    "\n",
    "            6 : {'mouse' : 'B18-383', 'datasets': ['OVA-CTLA4', 'OVA-Isotype'], 'chain':'VL'},\n",
    "            7 : {'mouse' : 'HA-uMT', 'datasets': ['OVA-CTLA4', 'OVA-Isotype'], 'chain':'VL'},\n",
    "            8 : {'mouse' : 'HA-WT', 'datasets': ['CGG-CTLA4', 'CGG-Isotype'], 'chain':'VL'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "433ca1c1-bcf5-45e3-9dbf-21f8cd774422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Published_B18_Passenger_VH_-', 'LateGC_B18-383_APC_VH_-', 'LateGC_B18-383_CGG_VH_-', 'LateGC_B18-383_OVA_VH_-'}\n",
      "Mode : 1 B18-383 VH ['OVA', 'APC', 'CGG', 'Passenger']\n",
      "{'B18', 'B18-383'} {'VH'} {'Passenger', 'OVA', 'APC', 'CGG'}\n",
      "OVA:141\n",
      "APC:95\n",
      "CGG:48\n",
      "Passenger:6461\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['OVA_frequency', 'APC_frequency', 'CGG_frequency', 'Passenger_frequency']\n",
      "['OVA_plot_size', 'APC_plot_size', 'CGG_plot_size', 'Passenger_plot_size']\n",
      "['OVA_selec_uneven', 'APC_selec_uneven', 'CGG_selec_uneven', 'Passenger_selec_uneven']\n",
      "top 10 of:OVA_frequency\n",
      "top 10 of:APC_frequency\n",
      "top 10 of:CGG_frequency\n",
      "top 10 of:Passenger_frequency\n",
      "# Mode : 1 B18-383 VH ['OVA', 'APC', 'CGG', 'Passenger'] \n",
      "# uniques : 0.015477480266212661 10.526315789473683 0.1 0.1 \n",
      "# shareds : 0.1547748026621266 75.177304964539 0.006976377974472255 0.9154449388600349 \n",
      "# uq/shd : 0.015477480266212661 75.177304964539 0.006976377974472255 0.9154449388600349\n",
      "OVA\n",
      "APC\n",
      "CGG\n",
      "Passenger\n",
      "{'LateGC_HA-uMT_APC_VH_0-1', 'LateGC_HA-uMT_OVA_VH_0-1', 'LateGC_HA-WT_mix_VH_1-1', 'LateGC_HA-uMT_CGG_VH_0-1'}\n",
      "Mode : 2 HA-WT VH ['OVA', 'APC', 'CGG', 'mix']\n",
      "{'HA-WT', 'HA-uMT'} {'VH'} {'mix', 'OVA', 'APC', 'CGG'}\n",
      "OVA:70\n",
      "APC:28\n",
      "CGG:45\n",
      "mix:84\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['OVA_frequency', 'APC_frequency', 'CGG_frequency', 'mix_frequency']\n",
      "['OVA_plot_size', 'APC_plot_size', 'CGG_plot_size', 'mix_plot_size']\n",
      "['OVA_selec_uneven', 'APC_selec_uneven', 'CGG_selec_uneven', 'mix_selec_uneven']\n",
      "top 10 of:OVA_frequency\n",
      "top 10 of:APC_frequency\n",
      "top 10 of:CGG_frequency\n",
      "top 10 of:mix_frequency\n",
      "# Mode : 2 HA-WT VH ['OVA', 'APC', 'CGG', 'mix'] \n",
      "# uniques : 1.1904761904761905 35.55555555555556 0.1 0.1 \n",
      "# shareds : 1.1904761904761905 71.11111111111111 0.021003500583430573 0.7744165946413138 \n",
      "# uq/shd : 1.1904761904761905 71.11111111111111 0.021003500583430573 0.7744165946413138\n",
      "OVA\n",
      "APC\n",
      "CGG\n",
      "mix\n",
      "{'LateGC_B18-383_OVA-CTLA4_VH_-', 'LateGC_B18-383_OVA-Isotype_VH_-'}\n",
      "Mode : 3 B18-383 VH ['OVA-CTLA4', 'OVA-Isotype']\n",
      "{'B18-383'} {'VH'} {'OVA-Isotype', 'OVA-CTLA4'}\n",
      "OVA-CTLA4:122\n",
      "OVA-Isotype:155\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['OVA-CTLA4_frequency', 'OVA-Isotype_frequency']\n",
      "['OVA-CTLA4_plot_size', 'OVA-Isotype_plot_size']\n",
      "['OVA-CTLA4_selec_uneven', 'OVA-Isotype_selec_uneven']\n",
      "top 10 of:OVA-CTLA4_frequency\n",
      "top 10 of:OVA-Isotype_frequency\n",
      "# Mode : 3 B18-383 VH ['OVA-CTLA4', 'OVA-Isotype'] \n",
      "# uniques : 0.6451612903225806 10.32258064516129 0.1 0.1 \n",
      "# shareds : 0.6451612903225806 82.58064516129032 0.0418956043956044 0.9581043956043956 \n",
      "# uq/shd : 0.6451612903225806 82.58064516129032 0.0418956043956044 0.9581043956043956\n",
      "OVA-CTLA4\n",
      "OVA-Isotype\n",
      "{'LateGC_HA-uMT_OVA-Isotype_VH_0-1', 'LateGC_HA-uMT_OVA-CTLA4_VH_0-1'}\n",
      "Mode : 4 HA-uMT VH ['OVA-CTLA4', 'OVA-Isotype']\n",
      "{'HA-uMT'} {'VH'} {'OVA-Isotype', 'OVA-CTLA4'}\n",
      "OVA-CTLA4:60\n",
      "OVA-Isotype:53\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['OVA-CTLA4_frequency', 'OVA-Isotype_frequency']\n",
      "['OVA-CTLA4_plot_size', 'OVA-Isotype_plot_size']\n",
      "['OVA-CTLA4_selec_uneven', 'OVA-Isotype_selec_uneven']\n",
      "top 10 of:OVA-CTLA4_frequency\n",
      "top 10 of:OVA-Isotype_frequency\n",
      "# Mode : 4 HA-uMT VH ['OVA-CTLA4', 'OVA-Isotype'] \n",
      "# uniques : 1.6666666666666667 28.333333333333332 0.1 0.1 \n",
      "# shareds : 1.6666666666666667 77.35849056603774 0.055613850996852045 0.9443861490031479 \n",
      "# uq/shd : 1.6666666666666667 77.35849056603774 0.055613850996852045 0.9443861490031479\n",
      "OVA-CTLA4\n",
      "OVA-Isotype\n",
      "{'LateGC_HA-WT_CGG-CTLA4_VH_1-1000', 'LateGC_HA-WT_CGG-Isotype_VH_1-1000'}\n",
      "Mode : 5 HA-WT VH ['CGG-CTLA4', 'CGG-Isotype']\n",
      "{'HA-WT'} {'VH'} {'CGG-CTLA4', 'CGG-Isotype'}\n",
      "CGG-CTLA4:109\n",
      "CGG-Isotype:29\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['CGG-CTLA4_frequency', 'CGG-Isotype_frequency']\n",
      "['CGG-CTLA4_plot_size', 'CGG-Isotype_plot_size']\n",
      "['CGG-CTLA4_selec_uneven', 'CGG-Isotype_selec_uneven']\n",
      "top 10 of:CGG-CTLA4_frequency\n",
      "top 10 of:CGG-Isotype_frequency\n",
      "# Mode : 5 HA-WT VH ['CGG-CTLA4', 'CGG-Isotype'] \n",
      "# uniques : 0.9174311926605505 27.522935779816514 0.1 0.1 \n",
      "# shareds : 0.9174311926605505 40.36697247706422 0.036616161616161616 0.9633838383838383 \n",
      "# uq/shd : 0.9174311926605505 40.36697247706422 0.036616161616161616 0.9633838383838383\n",
      "CGG-CTLA4\n",
      "CGG-Isotype\n",
      "{'LateGC_B18-383_OVA-Isotype_VL_-', 'LateGC_B18-383_OVA-CTLA4_VL_-'}\n",
      "Mode : 6 B18-383 VL ['OVA-CTLA4', 'OVA-Isotype']\n",
      "{'B18-383'} {'VL'} {'OVA-Isotype', 'OVA-CTLA4'}\n",
      "OVA-CTLA4:168\n",
      "OVA-Isotype:273\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['OVA-CTLA4_frequency', 'OVA-Isotype_frequency']\n",
      "['OVA-CTLA4_plot_size', 'OVA-Isotype_plot_size']\n",
      "['OVA-CTLA4_selec_uneven', 'OVA-Isotype_selec_uneven']\n",
      "top 10 of:OVA-CTLA4_frequency\n",
      "top 10 of:OVA-Isotype_frequency\n",
      "# Mode : 6 B18-383 VL ['OVA-CTLA4', 'OVA-Isotype'] \n",
      "# uniques : 0.3663003663003663 5.128205128205128 0.1 0.1 \n",
      "# shareds : 0.3663003663003663 33.33333333333333 0.05797101449275363 0.9420289855072465 \n",
      "# uq/shd : 0.3663003663003663 33.33333333333333 0.05797101449275363 0.9420289855072465\n",
      "OVA-CTLA4\n",
      "OVA-Isotype\n",
      "{'LateGC_HA-uMT_OVA-Isotype_VL_0-1', 'LateGC_HA-uMT_OVA-CTLA4_VL_0-1'}\n",
      "Mode : 7 HA-uMT VL ['OVA-CTLA4', 'OVA-Isotype']\n",
      "{'HA-uMT'} {'VL'} {'OVA-Isotype', 'OVA-CTLA4'}\n",
      "OVA-CTLA4:74\n",
      "OVA-Isotype:75\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['OVA-CTLA4_frequency', 'OVA-Isotype_frequency']\n",
      "['OVA-CTLA4_plot_size', 'OVA-Isotype_plot_size']\n",
      "['OVA-CTLA4_selec_uneven', 'OVA-Isotype_selec_uneven']\n",
      "top 10 of:OVA-CTLA4_frequency\n",
      "top 10 of:OVA-Isotype_frequency\n",
      "# Mode : 7 HA-uMT VL ['OVA-CTLA4', 'OVA-Isotype'] \n",
      "# uniques : 1.3333333333333335 22.972972972972975 0.1 0.1 \n",
      "# shareds : 1.3333333333333335 52.0 0.04936624416277519 0.9506337558372249 \n",
      "# uq/shd : 1.3333333333333335 52.0 0.04936624416277519 0.9506337558372249\n",
      "OVA-CTLA4\n",
      "OVA-Isotype\n",
      "{'LateGC_HA-WT_CGG-Isotype_VL_1-1000', 'LateGC_HA-WT_CGG-CTLA4_VL_1-1000'}\n",
      "Mode : 8 HA-WT VL ['CGG-CTLA4', 'CGG-Isotype']\n",
      "{'HA-WT'} {'VL'} {'CGG-CTLA4', 'CGG-Isotype'}\n",
      "CGG-CTLA4:162\n",
      "CGG-Isotype:51\n",
      "{'I': 20, 'V': 19, 'L': 18, 'F': 17, 'C': 16, 'M': 15, 'A': 14, 'W': 13, 'G': 12, 'T': 11, 'S': 10, 'Y': 9, 'P': 8, 'H': 7, 'N': 6, 'D': 5, 'Q': 4, 'E': 3, 'K': 2, 'R': 1}\n",
      "['CGG-CTLA4_frequency', 'CGG-Isotype_frequency']\n",
      "['CGG-CTLA4_plot_size', 'CGG-Isotype_plot_size']\n",
      "['CGG-CTLA4_selec_uneven', 'CGG-Isotype_selec_uneven']\n",
      "top 10 of:CGG-CTLA4_frequency\n",
      "top 10 of:CGG-Isotype_frequency\n",
      "# Mode : 8 HA-WT VL ['CGG-CTLA4', 'CGG-Isotype'] \n",
      "# uniques : 0.6172839506172839 19.1358024691358 0.1 0.1 \n",
      "# shareds : 0.6172839506172839 55.55555555555556 0.07296137339055794 0.927038626609442 \n",
      "# uq/shd : 0.6172839506172839 55.55555555555556 0.07296137339055794 0.927038626609442\n",
      "CGG-CTLA4\n",
      "CGG-Isotype\n",
      "Finished successfully!\n"
     ]
    }
   ],
   "source": [
    "# Section7: frquency and privacy index calculations and scatter plots\n",
    "# used in Figs 4D, 4E, 4G, 5I, 6H, S4D, S5C\n",
    "\n",
    "for mode in modes_dic.keys():\n",
    "\n",
    "    df_nts=pd.read_csv('{}/dfs_expanded_aas_excluded.tsv'.format(output_folder_prep), sep='\\t', header=0, low_memory=False)\n",
    "    mouse=modes_dic[mode]['mouse']\n",
    "    datasets=modes_dic[mode]['datasets']\n",
    "    chain=modes_dic[mode]['chain']\n",
    "    datasets\n",
    "\n",
    "\n",
    "    df_nts\n",
    "\n",
    "    df_aa=pd.read_csv('{}/df_aa_mode{}_{}.tsv'.format(output_folder_prep_plots, mode, chain), sep='\\t', header=0, low_memory=False, index_col=0)\n",
    "    df_aa=df_aa.iloc[:-3,:].copy()\n",
    "    \n",
    "    if mode == 1:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_B18-383_OVA_VH_-') |\\\n",
    "        (df_nts['label']=='LateGC_B18-383_APC_VH_-') |\\\n",
    "        (df_nts['label']=='LateGC_B18-383_CGG_VH_-') |\\\n",
    "        (df_nts['label']=='Published_B18_Passenger_VH_-') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))\n",
    "        chain='VH'\n",
    "    \n",
    "    elif mode == 2:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_HA-uMT_OVA_VH_0-1') |\\\n",
    "        (df_nts['label']=='LateGC_HA-uMT_APC_VH_0-1') |\\\n",
    "        (df_nts['label']=='LateGC_HA-uMT_CGG_VH_0-1') |\\\n",
    "        (df_nts['label']=='LateGC_HA-WT_mix_VH_1-1') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))\n",
    "        chain='VH'\n",
    "            \n",
    "    elif mode == 3:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_B18-383_OVA-CTLA4_VH_-') |\\\n",
    "        (df_nts['label']=='LateGC_B18-383_OVA-Isotype_VH_-') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))\n",
    "        chain='VH'\n",
    "    \n",
    "    elif mode == 4:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_HA-uMT_OVA-CTLA4_VH_0-1') |\\\n",
    "        (df_nts['label']=='LateGC_HA-uMT_OVA-Isotype_VH_0-1') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))\n",
    "        chain='VH'\n",
    "    \n",
    "    elif mode == 5:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_HA-WT_CGG-CTLA4_VH_1-1000') |\\\n",
    "        (df_nts['label']=='LateGC_HA-WT_CGG-Isotype_VH_1-1000') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))    \t\n",
    "        chain='VH'\n",
    "    \n",
    "    elif mode == 6:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_B18-383_OVA-CTLA4_VL_-') |\\\n",
    "        (df_nts['label']=='LateGC_B18-383_OVA-Isotype_VL_-') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))\n",
    "        chain='VL'\n",
    "    \n",
    "    elif mode == 7:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_HA-uMT_OVA-CTLA4_VL_0-1') |\\\n",
    "        (df_nts['label']=='LateGC_HA-uMT_OVA-Isotype_VL_0-1') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))\n",
    "        chain='VL'\n",
    "    \n",
    "    elif mode == 8:\n",
    "        df_nts=df_nts.loc[\n",
    "        (df_nts['label']=='LateGC_HA-WT_CGG-CTLA4_VL_1-1000') |\\\n",
    "        (df_nts['label']=='LateGC_HA-WT_CGG-Isotype_VL_1-1000') \\\n",
    "        ,].copy()\n",
    "        print(set(df_nts['label']))    \t\n",
    "        chain='VL'\n",
    "\n",
    "    print('Mode :', mode, mouse, chain, datasets)\n",
    "    \n",
    "    #Mode 1\n",
    "    # 5136 AA MM + AA nMM\n",
    "    # 4810 AA MM\n",
    "\n",
    "    print(set(df_nts['mouse']), set(df_nts['chain']), set(df_nts['dataset']))\n",
    "\n",
    "    for dataset in datasets:\n",
    "        print('{}:{}'.format(dataset, len(df_nts[df_nts['dataset']==dataset])))\n",
    "\n",
    "    # 2:3\n",
    "    # 3:7\n",
    "    # 4:15\n",
    "\n",
    "    all_combinations=list(np.arange(1.0,16.0)) #15\n",
    "\n",
    "    if len(datasets)==2:\n",
    "        cases_list_wanted_all={'shareds':[4.0], 'uniques':[1.0, 2.0], 'oxaxcx':[], 'remainders':[]}\n",
    "\n",
    "    if len(datasets)==3:\n",
    "        cases_list_wanted_all={'shareds':[7.0], 'uniques':[1.0, 2.0, 3.0], 'oxaxcx':[5.0, 6.0], 'remainders':[4.0]}\n",
    "\n",
    "    if len(datasets)==4:\n",
    "        cases_list_wanted_all={'shareds':[15.0], 'uniques':[1.0, 2.0, 3.0, 8.0], 'oxaxcx':[9.0, 10.0, 11.0], 'remainders':[4.0, 5.0, 6.0, 7.0, 12.0, 13.0, 14.0]}\n",
    "\n",
    "    dfs_cases_dic={}\n",
    "    dfs_cases_num_dic={}\n",
    "    for case, list_wanted in cases_list_wanted_all.items():\n",
    "\n",
    "        dic_num_blocks={}\n",
    "\n",
    "        list_exclusion=all_combinations.copy()\n",
    "        df_aa_now=df_aa.copy()\n",
    "\n",
    "        for i in list_wanted:\n",
    "            list_exclusion.remove(i)\n",
    "\n",
    "        for j in list_exclusion:\n",
    "            df_aa_now.replace({ j : np.nan}, inplace=True)\n",
    "\n",
    "        df_aa_now=df_aa_now.iloc[:-2,:]\n",
    "\n",
    "        for n in list_wanted:\n",
    "            dic_num_blocks[n]=(df_aa_now == n).sum().sum()\n",
    "        # print(case, dic_num_blocks)\n",
    "        dfs_cases_dic[case]=df_aa_now\n",
    "        dfs_cases_num_dic[case]=dic_num_blocks\n",
    "        # display(df_aa_now)\n",
    "\n",
    "    datasets\n",
    "\n",
    "    dfs_cases_num_dic\n",
    "\n",
    "    pd.DataFrame.from_dict(dfs_cases_num_dic, orient='index').T.to_csv('{}/mode{}_numbers_{}.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=True)\n",
    "\n",
    "    dfs_cases_dic.keys()\n",
    "\n",
    "    dfs_cases_dic['shareds']\n",
    "\n",
    "    df_pos_shareds = dfs_cases_dic['shareds'].T\n",
    "    df_pos_uniques = dfs_cases_dic['uniques'].T\n",
    "    df_pos_oxaxcx = dfs_cases_dic['oxaxcx'].T\n",
    "    df_pos_remainders = dfs_cases_dic['remainders'].T\n",
    "\n",
    "    # df_pos_uniques = pd.read_csv('../data/avneesh/affinity_birth/output/F005/mode{}-1_2_3_8.tsv'.format(mode), sep='\\t', header=0, low_memory=False, index_col=0)\n",
    "    # df_pos_all = pd.read_csv('../data/avneesh/affinity_birth/output/F005/mode{}-1_2_3_4_5_6_7_8_9_10_11_12_13_14_15.tsv'.format(mode), sep='\\t', header=0, low_memory=False, index_col=0)\n",
    "\n",
    "    # df_nts = pd.read_csv('../data/avneesh/affinity_birth/output/F002/all_nt_seq_based.tsv', sep='\\t', header=0, low_memory=False) #, index_col='codon'\n",
    "    # df_nts=df_nts[df_nts['frameshift']==False]\n",
    "    # df_nts=df_nts[df_nts['stopcodon']==False]\n",
    "\n",
    "    set(df_nts['dataset'])\n",
    "\n",
    "    # if mode==5:\n",
    "    #     df_now=pd.concat([df_nts[df_nts['dataset']=='1_1_OVA'], pd.concat([df_nts[df_nts['dataset']=='1_1_APC'],df_nts[df_nts['dataset']=='1_1_CGG']])])\n",
    "    #     df_now['dataset']='HA-WT'\n",
    "    #     df_nts=pd.concat([df_nts,df_now])\n",
    "\n",
    "\n",
    "\n",
    "    mouse\n",
    "\n",
    "    set(df_nts['mouse'])\n",
    "\n",
    "    aa_ref_seq=df_nts['ref_aa'].values[-1]\n",
    "\n",
    "    len_ref=len(df_nts['ref_aa'].values[-1])\n",
    "\n",
    "    df_nts\n",
    "\n",
    "    multiplier_size=22 # To increase the size of shapes on the plot\n",
    "    # df_nts.to_csv('{}/mode{}_relevant_dfs.tsv'.format(output_folder, mode), sep = '\\t', index=True)\n",
    "\n",
    "    # To translate AAs names to numbers to sort them by chemical properties\n",
    "    aa_D = dict()\n",
    "    aa_L=aas_chemistry_list\n",
    "    for y, aa in enumerate(aa_L):\n",
    "        aa_D[aa]=20-y\n",
    "    print(aa_D)\n",
    "\n",
    "    list_frequency=['{}_frequency'.format(ds) for ds in datasets]\n",
    "    list_plot_size=['{}_plot_size'.format(ds) for ds in datasets]\n",
    "    list_selec_uneven=['{}_selec_uneven'.format(ds) for ds in datasets]\n",
    "\n",
    "    print(list_frequency)\n",
    "    print(list_plot_size)\n",
    "    print(list_selec_uneven)\n",
    "\n",
    "    df_pos_uniques\n",
    "\n",
    "    df_aa=df_aa.T\n",
    "\n",
    "    df_nts['unique_num']=0\n",
    "    df_nts['shared_num']=0\n",
    "\n",
    "    # Uniques dataframe\n",
    "    myDict = dict()\n",
    "\n",
    "    ds_unique_names={1.0: 0, 2.0: 1, 3.0:2, 8.0:3} # For converting indices from 1238 to 0123\n",
    "\n",
    "    for p, aa in itertools.product(*[df_aa.index,df_aa.columns[:-2]]):\n",
    "        v = df_aa.loc[p,aa]\n",
    "        # if v not in [1.0,2.0,3.0,8.0]: continue\n",
    "        if v not in cases_list_wanted_all['uniques']: continue\n",
    "\n",
    "        # myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa' : aa}\n",
    "        myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa': aa, 'aa_n' : aa_D[aa]} # Translate AAs names to numbers to sort them by chemical properties\n",
    "\n",
    "        n = ds_unique_names[v] # Convert indexing 1238 to 0123\n",
    "\n",
    "        for i in df_nts[(df_nts['A{}'.format(p)]==aa) & (df_nts['dataset']==datasets[n])]['header'].index:\n",
    "            # print(i)\n",
    "            df_nts.loc[i,'unique_num']+=1\n",
    "\n",
    "        instances = len(df_nts[(df_nts['A{}'.format(p)]==aa) & (df_nts['dataset']==datasets[n])])\n",
    "        df_size = len(df_nts[df_nts[\"dataset\"]==datasets[n]])\n",
    "        df_frequency = instances/df_size*100\n",
    "\n",
    "        myDict['{}-{}'.format(p,aa)]['{}_instances'.format(datasets[n])] = instances\n",
    "        myDict['{}-{}'.format(p,aa)]['{}_size'.format(datasets[n])] = df_size\n",
    "\n",
    "        myDict['{}-{}'.format(p,aa)]['{}_frequency'.format(datasets[n])] = df_frequency\n",
    "        # myDict['{}-{}'.format(p,aa)]['{}_plot_size'.format(datasets[n])] = df_frequency*multiplier_size\n",
    "        myDict['{}-{}'.format(p,aa)]['{}_selec_uneven'.format(datasets[n])] = 0.1\n",
    "\n",
    "    df_all_uniques=pd.DataFrame.from_dict(myDict).transpose()\n",
    "    # display(df_all_uniques)\n",
    "    df_all_uniques['status']='uniques'\n",
    "\n",
    "    df_all_uniques['p']=df_all_uniques['p'].astype('int')+1 # Change the zero-indexing to one-indexing\n",
    "    df_all_uniques.to_csv('{}/mode{}_uniques_{}.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=True)\n",
    "\n",
    "    df_all_uniques\n",
    "\n",
    "    myDict = dict()\n",
    "\n",
    "    for p, aa in itertools.product(*[df_aa.index, df_aa.columns[:-2]]):\n",
    "        total_frequency = 0\n",
    "        v = df_aa.loc[p,aa]\n",
    "        # if v not in [9.0,10.0,11.0]: continue\n",
    "        if v not in cases_list_wanted_all['oxaxcx']: continue\n",
    "\n",
    "        # myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa' : aa}\n",
    "        myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa' : aa, 'aa_n' : aa_D[aa]}\n",
    "        for n in range(0, len(datasets)):\n",
    "            # print(n)\n",
    "            instances = len(df_nts[(df_nts['A{}'.format(p)]==aa) & (df_nts['dataset']==datasets[n])])\n",
    "            df_size = len(df_nts[df_nts[\"dataset\"]==datasets[n]])\n",
    "            df_frequency = instances/df_size*100\n",
    "            total_frequency+=df_frequency\n",
    "\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_instances'.format(datasets[n])] = instances\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_size'.format(datasets[n])] = df_size\n",
    "\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_frequency'.format(datasets[n])] = df_frequency\n",
    "            # myDict['{}-{}'.format(p,aa)]['{}_plot_size'.format(datasets[n])] = df_frequency*multiplier_size\n",
    "\n",
    "        for n in range(0, len(datasets)):\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_selec_uneven'.format(datasets[n])] = myDict['{}-{}'.format(p,aa)]['{}_frequency'.format(datasets[n])]/total_frequency\n",
    "\n",
    "    df_oxaxcx=pd.DataFrame()\n",
    "\n",
    "    if len(myDict)!=0:\n",
    "        df_oxaxcx=pd.DataFrame.from_dict(myDict).transpose()\n",
    "\n",
    "        df_oxaxcx['p']=df_oxaxcx['p'].astype('int')+1 # Change the zero-indexing to one-indexing\n",
    "\n",
    "        df_oxaxcx['status']='oxaxcx'\n",
    "        df_oxaxcx.to_csv('{}/mode{}_oxaxcx_{}.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=True)\n",
    "\n",
    "    df_oxaxcx\n",
    "\n",
    "    # Remainder Shareds dataframe\n",
    "    myDict = dict()\n",
    "\n",
    "    for p, aa in itertools.product(*[df_aa.index, df_aa.columns[:-2]]):\n",
    "        total_frequency = 0\n",
    "        v = df_aa.loc[p,aa]\n",
    "        if v not in cases_list_wanted_all['remainders']: continue\n",
    "\n",
    "        # myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa' : aa}\n",
    "        myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa' : aa, 'aa_n' : aa_D[aa]}\n",
    "        for n in range(0, len(datasets)):\n",
    "            # print(n)\n",
    "            instances = len(df_nts[(df_nts['A{}'.format(p)]==aa) & (df_nts['dataset']==datasets[n])])\n",
    "            df_size = len(df_nts[df_nts[\"dataset\"]==datasets[n]])\n",
    "            df_frequency = instances/df_size*100\n",
    "            total_frequency+=df_frequency\n",
    "\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_instances'.format(datasets[n])] = instances\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_size'.format(datasets[n])] = df_size\n",
    "\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_frequency'.format(datasets[n])] = df_frequency\n",
    "            # myDict['{}-{}'.format(p,aa)]['{}_plot_size'.format(datasets[n])] = df_frequency*multiplier_size\n",
    "\n",
    "        for n in range(0, len(datasets)):\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_selec_uneven'.format(datasets[n])] = myDict['{}-{}'.format(p,aa)]['{}_frequency'.format(datasets[n])]/total_frequency\n",
    "\n",
    "    df_remainders=pd.DataFrame()\n",
    "\n",
    "    if len(myDict)!=0:\n",
    "\n",
    "        df_remainders=pd.DataFrame.from_dict(myDict).transpose()\n",
    "\n",
    "        df_remainders['p']=df_remainders['p'].astype('int')+1 # Change the zero-indexing to one-indexing\n",
    "\n",
    "        df_remainders['status']='remainders'\n",
    "        df_remainders.to_csv('{}/mode{}_remainders_{}.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=True)\n",
    "\n",
    "    df_remainders\n",
    "\n",
    "    # Shareds dataframe\n",
    "    myDict = dict()\n",
    "\n",
    "    for p, aa in itertools.product(*[df_aa.index, df_aa.columns[:-2]]):\n",
    "        total_frequency = 0\n",
    "        v = df_aa.loc[p,aa]\n",
    "        if v not in cases_list_wanted_all['shareds']: continue\n",
    "\n",
    "        # myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa' : aa}\n",
    "        myDict['{}-{}'.format(p,aa)] = {'p': p, 'aa' : aa, 'aa_n' : aa_D[aa]}\n",
    "        for n in range(0, len(datasets)):\n",
    "            # print(n)\n",
    "\n",
    "            for i in df_nts[(df_nts['A{}'.format(p)]==aa) & (df_nts['dataset']==datasets[n])]['header'].index:\n",
    "                df_nts.loc[i,'shared_num']+=1\n",
    "                # print(datasets[n],i)\n",
    "            instances = len(df_nts[(df_nts['A{}'.format(p)]==aa) & (df_nts['dataset']==datasets[n])])\n",
    "\n",
    "            df_size = len(df_nts[df_nts[\"dataset\"]==datasets[n]])\n",
    "            df_frequency = instances/df_size*100\n",
    "            total_frequency+=df_frequency\n",
    "\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_instances'.format(datasets[n])] = instances\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_size'.format(datasets[n])] = df_size\n",
    "\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_frequency'.format(datasets[n])] = df_frequency\n",
    "            # myDict['{}-{}'.format(p,aa)]['{}_plot_size'.format(datasets[n])] = df_frequency*multiplier_size\n",
    "\n",
    "        for n in range(0, len(datasets)):\n",
    "            myDict['{}-{}'.format(p,aa)]['{}_selec_uneven'.format(datasets[n])] = myDict['{}-{}'.format(p,aa)]['{}_frequency'.format(datasets[n])]/total_frequency\n",
    "    df_all_shareds=pd.DataFrame.from_dict(myDict).transpose()\n",
    "    df_all_shareds['status']='shareds'\n",
    "\n",
    "    df_all_shareds['p']=df_all_shareds['p'].astype('int')+1 # Change the zero-indexing to one-indexing\n",
    "    df_all_shareds.to_csv('{}/mode{}_shareds_{}.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=True)\n",
    "    df_all_shareds\n",
    "\n",
    "    grouping=df_nts.groupby(by='dataset')\n",
    "    dfs_unique_num=pd.DataFrame()\n",
    "    dfs_shared_num=pd.DataFrame()\n",
    "\n",
    "    for ds, df_now in grouping:\n",
    "        cols=['{}_unique_num'.format(ds), '{}_shared_num'.format(ds)]\n",
    "        df_now.rename(columns={'unique_num':cols[0], 'shared_num':cols[1]}, inplace=True)\n",
    "        df_now=df_now[[cols[0], cols[1]]]\n",
    "\n",
    "        df_now=df_now.sort_values(by=cols[0], ascending=False)\n",
    "        df_now.reset_index(inplace=True, drop=True)\n",
    "        dfs_unique_num=pd.concat([dfs_unique_num, df_now[cols[0]]], axis=1)\n",
    "\n",
    "        df_now=df_now.sort_values(by=cols[1], ascending=False)\n",
    "        df_now.reset_index(inplace=True, drop=True)\n",
    "        dfs_shared_num=pd.concat([dfs_shared_num, df_now[cols[1]]], axis=1)\n",
    "\n",
    "    list_dfs_unique_num=['{}_unique_num'.format(ds) for ds in datasets]\n",
    "    dfs_unique_num[list_dfs_unique_num].to_csv('{}/mode{}_unique_num_{}_aa.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=False)\n",
    "\n",
    "    list_dfs_shared_num=['{}_shared_num'.format(ds) for ds in datasets]\n",
    "    dfs_shared_num[list_dfs_shared_num].to_csv('{}/mode{}_shared_num_{}_aa.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=False)\n",
    "\n",
    "    # raise Exception(\"Stop!\")\n",
    "\n",
    "    n=10\n",
    "    for c in list_frequency:\n",
    "        print('top {} of:{}'.format(n, c))\n",
    "        df_now=df_all_shareds.dropna().sort_values(by=c, ascending=False).iloc[0:n,]\n",
    "        df_now=df_now[['p', 'aa']+list_frequency]\n",
    "        # display(df_now)\n",
    "\n",
    "        df_now.to_csv('{}/mode{}_top_{}_shared_{}_{}.tsv'.format(output_folder_scatter_plots, mode, n, c, chain), sep = '\\t', index=False)\n",
    "\n",
    "\n",
    "    df_all_shareds\n",
    "\n",
    "    # Calculating min/max ranges for uniform size/intensity plotting\n",
    "    min_frequency_uq=df_all_uniques[list_frequency].min(axis=0).min()\n",
    "    max_frequency_uq=df_all_uniques[list_frequency].max(axis=0).max()\n",
    "\n",
    "    min_selec_uneven_uq=df_all_uniques[list_selec_uneven].min(axis=0).min()\n",
    "    max_selec_uneven_uq=df_all_uniques[list_selec_uneven].max(axis=0).max()\n",
    "\n",
    "    # print('uniques :', min_frequency_uq, max_frequency_uq, min_selec_uneven_uq, max_selec_uneven_uq)\n",
    "\n",
    "    min_frequency_shd=df_all_shareds[list_frequency].min(axis=0).min()\n",
    "    max_frequency_shd=df_all_shareds[list_frequency].max(axis=0).max()\n",
    "\n",
    "    min_selec_uneven_shd=df_all_shareds[list_selec_uneven].min(axis=0).min()\n",
    "    max_selec_uneven_shd=df_all_shareds[list_selec_uneven].max(axis=0).max()\n",
    "\n",
    "    # print('shareds :', min_frequency_shd, max_frequency_shd, min_selec_uneven_shd, max_selec_uneven_shd)\n",
    "\n",
    "    min_frequency=min(min_frequency_uq, min_frequency_shd)\n",
    "    max_frequency=max(max_frequency_uq, max_frequency_shd)\n",
    "\n",
    "    min_selec_uneven=min(min_selec_uneven_uq, min_selec_uneven_shd)\n",
    "    max_selec_uneven=max(max_selec_uneven_uq, max_selec_uneven_shd)\n",
    "\n",
    "    print('# Mode :', mode, mouse, chain, datasets,\\\n",
    "          '\\n# uniques :', min_frequency_uq, max_frequency_uq, min_selec_uneven_uq, max_selec_uneven_uq,\\\n",
    "          '\\n# shareds :', min_frequency_shd, max_frequency_shd, min_selec_uneven_shd, max_selec_uneven_shd,\\\n",
    "          '\\n# uq/shd :', min_frequency, max_frequency, min_selec_uneven, max_selec_uneven)\n",
    "\n",
    "    multi_index = pd.MultiIndex.from_tuples([('min', 'frequency'),('max', 'frequency'),\n",
    "                                             ('min', 'selec_uneven'),('max', 'selec_uneven')])\n",
    "\n",
    "    df_min_max = pd.DataFrame(index=multi_index, columns=['uniques','shareds', 'oxaxcx', 'remainders'])\n",
    "\n",
    "    df_min_max.loc[('min', 'frequency'), 'uniques'] = min_frequency_uq\n",
    "    df_min_max.loc[('max', 'frequency'), 'uniques'] = max_frequency_uq\n",
    "    df_min_max.loc[('min', 'selec_uneven'), 'uniques'] = min_selec_uneven_uq\n",
    "    df_min_max.loc[('max', 'selec_uneven'), 'uniques'] = max_selec_uneven_uq\n",
    "\n",
    "    df_min_max.loc[('min', 'frequency'), 'shareds'] = min_frequency_shd\n",
    "    df_min_max.loc[('max', 'frequency'), 'shareds'] = max_frequency_shd\n",
    "    df_min_max.loc[('min', 'selec_uneven'), 'shareds'] = min_selec_uneven_shd\n",
    "    df_min_max.loc[('max', 'selec_uneven'), 'shareds'] = max_selec_uneven_shd\n",
    "\n",
    "    df_min_max.loc[('min', 'frequency'), 'oxaxcx'] = min_frequency_shd\n",
    "    df_min_max.loc[('max', 'frequency'), 'oxaxcx'] = max_frequency_shd\n",
    "    df_min_max.loc[('min', 'selec_uneven'), 'oxaxcx'] = min_selec_uneven_shd\n",
    "    df_min_max.loc[('max', 'selec_uneven'), 'oxaxcx'] = max_selec_uneven_shd\n",
    "\n",
    "    df_min_max.loc[('min', 'frequency'), 'remainders'] = min_frequency_shd\n",
    "    df_min_max.loc[('max', 'frequency'), 'remainders'] = max_frequency_shd\n",
    "    df_min_max.loc[('min', 'selec_uneven'), 'remainders'] = min_selec_uneven_shd\n",
    "    df_min_max.loc[('max', 'selec_uneven'), 'remainders'] = max_selec_uneven_shd\n",
    "\n",
    "    df_min_max.to_csv('{}/mode{}_df_min_max_{}.tsv'.format(output_folder_scatter_plots, mode, chain), sep = '\\t', index=True)\n",
    "    df_min_max\n",
    "\n",
    "    min_frequency=0\n",
    "    max_frequency=100\n",
    "    min_selec_uneven=0\n",
    "    max_selec_uneven=1.25\n",
    "\n",
    "    intensity_range=np.linspace(min_selec_uneven, max_selec_uneven, 6, endpoint=True)\n",
    "    intensity_range=[1.5,1,.75,.5,.25,.01]\n",
    "    size_range=np.linspace(min_frequency, max_frequency, 6, endpoint=True)\n",
    "    size_range=[150,100,75,50,25,1]\n",
    "    aa_range=[3,8,10,12,14,16]\n",
    "\n",
    "    intensity_range\n",
    "\n",
    "    size_range\n",
    "\n",
    "    dfs=[df_all_shareds, df_oxaxcx, df_remainders, df_all_uniques]\n",
    "    statuses=['shareds', 'oxaxcx', 'remainders', 'uniques']\n",
    "\n",
    "    for p, df_now, status in zip([len_ref+3, len_ref+5, len_ref+7, len_ref+9], dfs, statuses):\n",
    "\n",
    "        for P, A, S, I in zip([p]*6, aa_range, size_range, [1]*6):\n",
    "            if status=='uniques': I=0.1\n",
    "            df_now.loc['m{}S_{}I-{}'.format(S,I,P), 'p'] = P\n",
    "            df_now.loc['m{}S_{}I-{}'.format(S,I,P), 'aa_n'] = A\n",
    "            df_now.loc['m{}S_{}I-{}'.format(S,I,P), 'status'] = status\n",
    "\n",
    "            for c in list_frequency:\n",
    "                df_now.loc['m{}S_{}I-{}'.format(S,I,P), c] = S\n",
    "            for c in list_selec_uneven:\n",
    "                df_now.loc['m{}S_{}I-{}'.format(S,I,P), c] = I\n",
    "        # display(df_now)\n",
    "        for P, A, S, I in zip([p+9]*6, aa_range, [max_frequency*2/3]*6, intensity_range):\n",
    "            if status=='uniques':\n",
    "                I=0.1\n",
    "                A=8\n",
    "            df_now.loc['m{}S_{}I-{}'.format(S,I,P), 'p'] = P\n",
    "            df_now.loc['m{}S_{}I-{}'.format(S,I,P), 'aa_n'] = A\n",
    "            df_now.loc['m{}S_{}I-{}'.format(S,I,P), 'status'] = status\n",
    "\n",
    "            for c in list_frequency:\n",
    "                df_now.loc['m{}S_{}I-{}'.format(S,I,P), c] = S\n",
    "            for c in list_selec_uneven:\n",
    "                df_now.loc['m{}S_{}I-{}'.format(S,I,P), c] = I\n",
    "\n",
    "    # Calculate shape sizes for ploting\n",
    "    for n, ds_pl in itertools.product(*[range(0, len(datasets)), dfs]):\n",
    "        ds_pl['{}_plot_size'.format(datasets[n])]=ds_pl['{}_frequency'.format(datasets[n])]*multiplier_size\n",
    "\n",
    "    # df_all_shareds[df_all_shareds['p']==len_ref+3]\n",
    "\n",
    "    # df_oxaxcx[df_oxaxcx['p']==len_ref+5]\n",
    "\n",
    "    # df_remainders[df_remainders['p']==len_ref+7]\n",
    "\n",
    "    # df_all_uniques[df_all_uniques['p']==len_ref+9]\n",
    "\n",
    "    plot_dic={'shareds': df_all_shareds, 'uniques': df_all_uniques, 'oxaxcx': df_oxaxcx, 'remainders': df_remainders}\n",
    "\n",
    "    # 'Orange' is not a valid value for cmap; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r',\n",
    "    # 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r',\n",
    "    # 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r',\n",
    "    # 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2',\n",
    "    # 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot',\n",
    "    # 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r',\n",
    "    # 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat',\n",
    "    # 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r',\n",
    "    # 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r',\n",
    "    # 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r',\n",
    "    # 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r',\n",
    "    # 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r'\n",
    "\n",
    "    Legend=False\n",
    "    for ds in datasets:\n",
    "        print(ds)\n",
    "        plt.rc('font', size=30)\n",
    "\n",
    "        kwargs  =   {'edgecolor' : \"gray\", # for edge color\n",
    "                     'linewidth' : 0.3, # line width of spot\n",
    "                     'linestyle' : '-', # line style of spot\n",
    "                    }\n",
    "\n",
    "        cmap = {'shareds':'Reds', 'uniques':'spring', 'oxaxcx':'Greens', 'remainders':'Blues'}\n",
    "\n",
    "        if ds==datasets[0] or ds==datasets[-1]: fig, ax = plt.subplots(figsize=(45,8.5))\n",
    "        else: fig, ax = plt.subplots(figsize=(45,8))\n",
    "\n",
    "\n",
    "\n",
    "        for status, df_plot in plot_dic.items(): #df shareds or uniques\n",
    "            df_plot = df_plot[['p', 'aa_n', 'status', '{}_plot_size'.format(ds), '{}_selec_uneven'.format(ds)]].dropna() #, '{}_frequency'.format(ds)\n",
    "            # df.to_csv('{}/mode{}_{}_df.tsv'.format(output_folder, mode, ds), sep = '\\t', index=True)\n",
    "\n",
    "            # display(df_plot)\n",
    "            # print(len(df_plot))\n",
    "            # print(status)\n",
    "            # s=np.arange(1,111)\n",
    "\n",
    "            # xx=df_plot['{}_plot_size'.format(ds)]\n",
    "            # xx=[x * 30 for x in xx]\n",
    "            # print(xx, len(xx))\n",
    "            ax.scatter(\n",
    "                df_plot['p'], df_plot['aa_n'],\n",
    "                s=list(df_plot['{}_plot_size'.format(ds)]), c=df_plot['{}_selec_uneven'.format(ds)], cmap=cmap[status], **kwargs,# color=color,, marker=marker,\n",
    "                label=status,\n",
    "            )\n",
    "\n",
    "        plt.xticks([])\n",
    "\n",
    "        if ds==datasets[0]:\n",
    "\n",
    "            plt.tick_params(which='both', top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "            # plt.tick_params(which='minor', top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "            plt.xticks(ticks=range(1,len_ref+1, 1), labels=list(aa_ref_seq), minor=False)\n",
    "            plt.xticks(ticks=range(2,len_ref+1, 2), minor=True)\n",
    "            plt.xticks(fontsize=40)\n",
    "            plt.xticks(fontsize=40)\n",
    "\n",
    "        if ds==datasets[-1]:\n",
    "\n",
    "            plt.tick_params(which='both', top=False, labeltop=False, bottom=True, labelbottom=True)\n",
    "            # plt.tick_params(which='minor', top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "            plt.xticks(ticks=range(0,len_ref+0, 5), labels=range(0,len_ref+0, 5), minor=False)\n",
    "            plt.xticks(ticks=range(1,len_ref+1, 1), minor=True)\n",
    "            plt.xticks(fontsize=40)\n",
    "\n",
    "        # plt.xticks([])\n",
    "        # if ds=='Passenger':\n",
    "        #     plt.xticks(range(0,len_ref+1,2))\n",
    "        #     # plt.minorticks_on(labelbottom=False)\n",
    "        # if ds=='OVA':\n",
    "        #     plt.xticks(range(1,len_ref+1), aa_ref_seq)\n",
    "        #     plt.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "        plt.yticks(range(20,0,-1), aa_L)\n",
    "        plt.xlim([0.5, len_ref+1])\n",
    "        if Legend==True: plt.xlim([0.5, len_ref+20])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # plt.title(\"title\")\n",
    "        # plt.xlabel('Positions (1-{})'.format(len_ref), )\n",
    "        # plt.xlabel('')\n",
    "        plt.ylabel('Amino acids', weight='bold')\n",
    "        plt.ylabel('')\n",
    "\n",
    "        # plt.grid(color='lightgray', linestyle='-', linewidth=0.5, axis='both')\n",
    "        plt.savefig('{}/mode{}-{}-{}.jpg'.format(output_folder_scatter_plots, mode, ds, chain, dpi=150))\n",
    "        plt.close(fig)\n",
    "        time.sleep(0.1)\n",
    "        plt.pause(0.0001)\n",
    "\n",
    "\n",
    "# raise Exception(\"Stop!\")\n",
    "\n",
    "\n",
    "print('Finished successfully!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fe6413-6f74-41a8-a05e-d7d7431cd942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90664d-d29c-4a95-af54-369cf1a98524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
